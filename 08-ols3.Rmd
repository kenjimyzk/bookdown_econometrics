---
output: 
  html_document:default
  html_notebook:default
---

# 現代的仮定のもとでの最小二乗法
```{r include=FALSE}
rm(list = ls())
library(knitr)
opts_chunk$set(echo = TRUE,error = FALSE,warning = FALSE,collapse = TRUE,cache = TRUE,cache.extra = rand_seed, autodep = TRUE)
``` 

```{r}
set.seed(2000)
library(AER)
library(mosaic)
#library(latticeExtra)
library(broom)
```


前節において以下の仮定を置いていた.

+ $(x_i,y_i)$ は独立同一分布にしたがう.
+ $E[u_i]=0$ である.
+ $u_i$ と $x_i$ は独立である.
+ $u_i$ は正規分布にしたがう.

これらの仮定を緩めることで分析にどのような影響をあたえるのかを見ていく.

仮想的に以下のモデルを考える.
```{r}
data("Journals", package = "AER")
df <- Journals %>% 
  mutate(citeprice = price/citations,
         age = 2000 - foundingyear) %>%
  select(subs,citeprice,age)
inspect(df)
```
 
作図すると以下である.
```{r}
gf_point(log(subs)~log(citeprice),data=df)
```

## 正規性の仮定について
十分な観測値が得られるばあい, $u_i$ が正規分布にしたがっていないくても, 中心極限定理定理より, 最小二乗法推定量は正規分布に近似できる.

```{r}
simdata <- function(N = 100) {
  x <- rnorm(N, mean = 10, sd = 1)
  u <- runif(N, -10,10)
  y <- 1 + x + u
  data.frame(x,y)
}

siml <- do(1000) * {lm(y~x,data=simdata(100)) %>% tidy() %>%
    filter(term == "x") %>% select(estimate, std.error) %>%
    mutate(tval = (estimate-1)/std.error)
  }
```


```{r}
gf_dhistogram(~tval, data= siml) %>% 
  gf_dist("norm")
```

ここの係数ゼロのティー検定について, ライブラリ `AER` を導入して `coeftest` を用いればよい.
```{r}
fm1 <- lm(log(subs)~log(citeprice)*log(age),data=df)
coeftest(fm1,df=Inf)
```
ただ十分なデータのもとではティー値のままでもよい.

同様に複数制約の場合, エフ検定統計量に制約の数を乗じた統計量が
自由度が制約数のカイ二乗分布にしたがうことが知られている.
これをR で実施するには `waldtest` を用いればよい. 
```{r}
fm0 <- lm(log(subs)~log(citeprice),data=df)
waldtest(fm0,fm1,test="Chisq")
```
エフ検定も十分なデータのもとではそのままでよいであろう.

オプション `test` を付けなければエフ検定を実施する.
```{r}
waldtest(fm0,fm1)
```
これは `anova` と同じである.
```{r}
anova(fm0,fm1)
```

複数制約の検定としてLM検定というのもある.
制約付きの回帰分析を実行し, その残差を制約なしのモデルの説明変数に回帰する.
その決定係数に観測数を掛けた統計量が自由どが制約の数のカイ二乗分布にしたがうことが知られている.
```{r}
lmt <- lm(I(resid(fm0))~log(age)*log(citeprice),data=df) %>%
  rsquared() * nrow(df)
lmt
1-pchisq(lmt,df=1)
```

## 誤差項と説明変数が独立の仮定について
また $u_i$ と $x_i$ は独立でなく, $u_i$ と $x_i$ が無相関という弱い条件のもとでも,
一致推定量であることが知られている.
ただ不偏推定量は保証できない. また 線形推定量のなかで最小の分散とも言えない.^[
正確にいえば, 不偏推定量のとめには条件付き期待値が説明変数に依存しないことが必要である. また線形推定量のなかで最小の分散になるためには
条件付き分散が説明変数に依存しないことが必要である. ]
また独立のときの標準誤差の推定量が一致推定量でない.

もし分散の形状がわかっているならば加重最小自乗法を使えばよい.
たとえば, 単回帰モデル
$$
y_i = \alpha + \beta x_i + u_i
$$
で誤差項が $u_i=x_i v_i$ として, $x_i$ と $v_i$ が独立で, $v_i$の分散が $V[v_i]=\sigma^2$ とする.
このとき 誤差項は平均ゼロで無相関であるが独立ではない.
また条件付き分散は $V[u_i|x_i]=\sigma^2 x_i^2$ である.
このとき
$$
\frac{y_i}{x_i} = \alpha\frac{1}{x_i} + \beta + u_i
$$
として, 回帰分析をおこなえばよい.

R ではウェイトをつけたい変数をオプションとして指定して `lm` を実施すればよい.
なおウェイトは数量のみなので, カテゴリカル変数の場合は変換する必要がある.
```{r}
fm_w1 <- lm(log(subs)~log(citeprice), data=df,weight = 1/citeprice)
summary(fm_w1)
```

```{r}
fn <- makeFun(fm0)
fn_w1 <- makeFun(fm_w1)
fm_w2 <- lm(log(subs)~log(citeprice), data=df,weight = 1/citeprice^2)
fn_w2 <- makeFun(fm_w2)
gf_point(log(subs)~log(citeprice),data = df) %>%
  gf_fun(log(fn(exp(x)))~x,color="blue") %>%
  gf_fun(log(fn_w1(exp(x)))~x,color="red") %>%
  gf_fun(log(fn_w2(exp(x)))~x,color = "green")
```


しかしながら一般的には分散の形状は不明である.
その場合, 別の分散のもとで正規分布に近似できることがしられている.^[
正確には観測される変数に4次のモーメントが存在するという仮定が必要となる.
この仮定の直感的な意味は異常値が存在しないことである.]
つまり, 説明変数と誤差項が無相関であるが, 独立とまでは言い切れない場合,
最小二乗推定量を実行した際, 別の方法で分散を推定する必要がある.
この別の分散をロバスト分散という.

R でロバスト分散を推定するにはパッケージ `AER` を導入するのが簡単である.
は次のコマンド `coeftest` を実行すればよい.
```{r}
coeftest(fm1,vcov=vcovHC)
```

先の値と標準誤差が違っていることが確認できるであろう.
ただこの値は STATA と少し異なっている. STATA と同じにするには
```{r}
coeftest(fm1,vcov=vcovHC(fm1,type="HC1"))
```
としなければならない.

またティー分布でなく正規分布とすることもできる.
```{r}
coeftest(fm0,vcov=vcovHC,df=Inf)
```

複数の係数についての検定は `waldtest` を実行すればよい.
```{r}
waldtest(fm0,fm1,vcov=vcovHC)
```

先の結果はエフ検定であるが, カイ二乗検定を実施するには以下を実施すればよい.
```{r}
waldtest(fm0,fm1,vcov=vcovHC, test="Chisq")
```

## 分散不均一のシミュレーション
```{r}
simdata <- function(N = 100) {
  x <- rnorm(N, mean = 10, sd = 1)
  u <- exp(x)*rnorm(N)
  y <- 1 + x + u
  data.frame(x,y)
}

siml <- do(1000) * {
  lm(y~x,data=simdata(100)) %>% tidy() %>%
    filter(term == "x") %>% select(estimate, std.error) %>%
    mutate(tval = (estimate-1)/std.error)
  }
```

通常の回帰分析を実施すると, 係数が不偏であっても, 正しく分散が推計できていないことが明らかである.
```{r}
gf_dhistogram(~tval, data = siml) %>%
  gf_lims(x = c(-4,4),y=c(0,0.5)) %>%
  gf_dist("norm")
```

加重最小自乗法を実施したシミュレーションを実施する.
```{r}
siml <- do(1000) * {
  lm(y~x,data=simdata(100), weight = 1/exp(x)) %>% tidy() %>%
    filter(term == "x") %>% select(estimate, std.error) %>%
    mutate(tval = (estimate-1)/std.error)
  }
```

加重最小自乗法を実施すると, 正規分布に近似できる.
```{r,fig}
gf_dhistogram(~tval, data = siml) %>%
  gf_lims(x = c(-4,4),y=c(0,0.5)) %>%
  gf_dist("norm")
```

ロバスト分散を利用したシミュレーションを実施する.
```{r}
siml <- do(1000) * {lm(y~x,data=simdata(100)) %>%
    coeftest(vcov=hccm) %>% tidy() %>%
    filter(term == "x") %>% select(estimate, std.error) %>%
    mutate(tval = (estimate-1)/std.error)
  }
```

ロバスト分散を利用した場合, 正規分布に近似できる.
```{r}
gf_dhistogram(~tval, data = siml) %>%
  gf_lims(x = c(-4,4),y=c(0,0.5)) %>%
  gf_dist("norm")
```



## 分散均一の検定
誤差項が説明変数と独立のときと無相関のときでは標準誤差の推定量が異なる.
正確にいうと, 条件付き分散が説明変数に依存するかどうかによって標準誤差の推定量が異なる. このことは分散均一と呼ばれている.

誤差項の分散が均一かどうかは検定可能である.
有名な検定方法としてBP (Breusch-Pagan) 検定というものがある.
BP検定は帰無仮説が分散均一で, 対立仮説が分散が説明変数と線形関係になっている場合の検定である.

残差の自乗を被説明変数として回帰分析をおこない,
その決定係数に観測数をかけたものが検定統計量となる.
```{r}
bpt <- lm(I(resid(fm1)^2)~log(age)*log(citeprice), data=df) %>%
  rsquared() * nrow(df)
bpt
1-pchisq(bpt,df=3)
```

ここでの例ではP値が5%を超えているので帰無仮説を棄却できないので,
分散均一を仮定してよいことが示唆されている.

R では以下のように実施すればよい.
```{r}
bptest(fm1)
```

これまでのBPテストは誤差項の分散が説明変数の線形関係あることを暗黙に仮定している.
非線形性を考慮するために説明変数の二次項を導入した分散不均一性の検定をホワイト検定という.
説明変数が複数ある場合ホワイト検定は煩雑になるため, 
被説明変数の予測値を使って計算することがある.
そのときホワイトテストは以下で実施する.
```{r}
wht <- lm(I(resid(fm1)^2)~fitted(fm1)+I(fitted(fm1)^2),data = df) %>%
  rsquared() * nrow(df)
wht
1-pchisq(wht,df=2)
```
ホワイト検定でも分散均一が示唆されている.

もしくは以下を実行する.
```{r}
bptest(fm1,~fitted(fm1)+I(fitted(fm1)^2))
```

このように分散均一性は検定することが可能であるが, そもそも分散均一が疑われる場合はロバスト分散で推定するので十分であるため,
最近の実証分析ではこの検定は実施せず, 最初からロバスト分散の結果を示すことが多い.


