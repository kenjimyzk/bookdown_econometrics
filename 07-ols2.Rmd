---
title: "R Notebook"
output:
  html_document: default
  html_notebook: default
---
# 重回帰
```{r include=FALSE}
rm(list = ls())
library(knitr)
opts_chunk$set(echo = TRUE,error = FALSE,warning = FALSE,collapse = TRUE,cache = TRUE,cache.extra = rand_seed, autodep = TRUE)
library(AER)
library(mosaic)
library(latticeExtra)
library(stargazer)
set.seed(2000)
``` 


## 最小二乗推定量
説明変数として $x$ と $w$ の2つを考えた線形モデルを考える.
$$
y = \alpha + \beta x +\gamma w+ u
$$

このようなモデルを重回帰モデルといい, 暗黙に次の仮定を置いている.

+ $(w_i, x_i,y_i)$ は独立同一分布にしたがう.
+ 誤差項の期待値はゼロである. $E[u_i]=0$ である.
+ 誤差項 $u_i$ は説明変数 $(x_i, w_i)$ に対して独立である.
+ 誤差項 $u_i$ は正規分布にしたがう.
+ 説明変数間に多重共線性は存在しない. つまり $x_i$ は $w_i$ の一次変換で表せない.

このとき最小二乗推定量は一致で, 不偏であり, 正規分布にしたがうことが知られている.

次のデータを考える.
```{r}
data(mtcars)
inspect(mtcars)
```

回帰分析の結果は以下である.
```{r}
fm <- lm( mpg ~ wt + hp, data = mtcars)
summary(fm)
```

回帰係数は `coef` で計算できる.
```{r}
(bhat <- coef(fm))
```

この係数は他の説明変数に回帰させたときの残差をもとめて,
それを説明変数に回帰したときの係数である.
```{r}
resid.wt <- resid(lm(wt~hp, data = mtcars))
coef(lm(mpg~resid.wt, data = mtcars))[2]
resid.hp <- resid(lm(hp~wt ,data = mtcars))
coef(lm(mpg~resid.hp, data = mtcars))[2]
```


予測値: $\hat{y_i}=\hat\alpha +\hat\beta x_i +\hat\gamma w_i$ は `fitted` で計算できる.
```{r}
head(fitted(fm))
```

残差: $\hat u_i = y_i - \hat y_i$ は `resid` で計算できる.
```{r}
head(resid(fm))
```

残差自乗和: $RSS = \sum \hat u_i^2$ は `deviance` で計算できる.
```{r}
sum(resid(fm)^2)
deviance(fm)
```

観測数を $n$, 説明変数の数を $k$ として, 自由度は $n-k-1$ であり,
$df.residual$ 計算できる.
```{r}
nobs(fm)
df.residual(fm)
```

回帰の標準誤差: $\hat\sigma =\sqrt{RSS/(n-k-1)}$ ($k=2$) は以下で計算できる
```{r}
sqrt(deviance(fm)/df.residual(fm))
summary(fm)$sigma
```

決定係数: $R^2 = 1-RSS/\sum \hat (y_i-\bar y)^2$ は以下で計算できる
```{r}
1-deviance(fm)/with(mtcars, sum((mpg-mean(mpg))^2))
summary(fm)$r.squared
mosaic::rsquared(fm)
```

修正済み決定係数: $\bar{R}^2 = 1-(RSS/(n-k-1))/(\sum \hat (y_i-\bar y)^2 /(n-1))$ ($k=2$) は以下で計算できる
```{r}
1-(deviance(fm)/df.residual(fm))/with(mtcars, var(mpg))
summary(fm)$adj.r.squared
```


### 予測

$wt=3$, $hp = 10$ のときの予測値は以下である.
```{r}
fn<-makeFun(fm)
fn(wt = 3, hp = 10)
```

作図の際, $hp=10$ のとき, 平均のもとの作図は作図は次のようにする.
青線が$hp=10$のときであり, 赤線が平均のときである.
```{r}
mhp = with(mtcars,mean(hp))
gf_point(mpg~wt,data=mtcars) %>%
  gf_fun(fn(wt,hp=10)~wt,color="blue") %>%
  gf_fun(fn(wt,hp=mhp)~wt,color="red")
```


## 除去変数バイアス

真のモデルが説明変数 `x` の単回帰モデルであるが,
`x` と正の相関がある `w` も観測できるとする. 
```{r}
simdata1 <- function(N = 100) {
  w <- rnorm(N, mean = 5, sd = 2)
  x <- w + rnorm(N, mean = 10, sd = 1)
  y <- 1 + x +  rnorm(N)
  data.frame(w,x,y)
}
```

このときの正しく推定した場合のシミュレーション結果である.
説明変数 `x` の係数の基本統計量と分布は以下である.
```{r}
siml <- do(1000) * lm(y~x, data = simdata1(100))
favstats(~x, data = siml)
gf_dhistogram(~x, data = siml) %>% gf_lims(x= c(0.5,1.5))
```

次に説明変数 `w` を付け加えたシミュレーション結果である.
説明変数 `x` の係数の基本統計量と分布は以下である.
```{r}
siml <- do(1000) * lm(y~x+w, data = simdata1(100))
favstats(~x, data = siml)
gf_histogram(~x, data = siml) %>% gf_lims(x= c(0.5,1.5))
```
分散が大きくなっているが, 不偏である.

説明変数 `w` の基本統計量係数の分布は以下である.
```{r}
favstats(~x, data = siml)
gf_histogram(~w, data = siml) %>% gf_lims(x= c(-1,1))
```
無関係な説明変数の分布は0の周りで不偏である.
両結果をまとめると, 多少推定が非効率になるが,
母集団モデルと無関係の変数を説明変数に加えても問題はおきない.

逆に必要な説明変数を重回帰モデルに入れなかったら,
最小二乗推定量は通常バイアスがかかる.
次のことが知られている:

+ 説明変数同士が無相関ならバイアスはない.
+ 説明変数同士の相関と, 含めている説明変数と被説明変数の相関が同じ符号なら, 正のバイアスが存在する.
+ 説明変数同士の相関と含めている説明変数と被説明変数の相関が異なる符号なら, 負のバイアスが存在する.

説明変数同士が正の相関の場合を考える.
```{r}
simdata2 <- function(N = 100) {
  w <- rnorm(N, mean = 5, sd = 2)
  x <- w + rnorm(N, mean = 10, sd = 1)
  y <- 1 + x + w + rnorm(N)
  data.frame(w,x,y)
}
```

正しい重回帰モデルの変数 $x$ の傾きの分布は以下であり, 不偏である.
```{r}
siml <- do(1000) * lm(y~x + w,data=simdata2(100))
gf_dhistogram(~x, data = siml) %>% gf_lims(x= c(0,3)) %>%
  gf_vline(xintercept=1,color="red")
```

単回帰モデルは不偏でなく正のバイアスが発生している.
```{r}
siml <- do(1000) * lm(y~x,data=simdata2(100))
gf_dhistogram(~x, data = siml) %>% gf_lims(x= c(0,3)) %>%
  gf_vline(xintercept=1,color="red")
```


まとめると, 真のモデルより多くの説明変数を加えても不偏性は保たれるが,
真のモデルより少ない説明変数の場合, 不偏性は保たれない.
多めの説明変数を加えたほうが望ましい結果が得られる.

一方, 似た説明変数を加える事によって多重共線性の問題が発生すると,
古い計量経済学のテキストでは書かれている.
サンプルが50程度ならその問題は重要であるが, 
1,000以上なら特に気にする必要はない.

## 回帰モデルの拡張
### 自乗項
```{r}
fm <- lm( mpg ~ wt + I(wt^2), data = mtcars)
summary(fm)
```

```{r, fig.keep="last"}
fn<-makeFun(fm)
xyplot(mpg~wt,data=mtcars)
plotFun(fn(wt)~wt,add=TRUE)
```


### ダミー変数
```{r}
fm <- lm( mpg ~ wt + factor(cyl), data = mtcars)
summary(fm)
```


```{r, fig.keep="last"}
fn <- makeFun(fm)
xyplot(mpg~wt, data = mtcars, group = factor(cyl))
plotFun(fn(wt, cyl = 4)~wt, col = 1, add = TRUE)
plotFun(fn(wt, cyl = 6)~wt, col = 2, add = TRUE)
plotFun(fn(wt, cyl = 8)~wt, col = 3, add = TRUE)
```

### 交差項
```{r}
fm <- lm( mpg ~ wt + factor(cyl) +wt:factor(cyl), data = mtcars)
summary(fm)
```

```{r}
fm0 <- lm( mpg ~ wt * factor(cyl), data = mtcars)
summary(fm0)
```

```{r, fig.keep="last"}
fn <- makeFun(fm)
xyplot(mpg~wt,data = mtcars,group = factor(cyl))
plotFun(fn(wt, cyl = 4)~wt, col = 1, add = TRUE)
plotFun(fn(wt, cyl = 6)~wt, col = 2, add = TRUE)
plotFun(fn(wt, cyl = 8)~wt, col = 3, add = TRUE)
```

## エフ検定
仮想的に以下のようにデータを生成する.
```{r}
N <- 100
x <- runif(N)
w <- sample(c("H","T"),N,replace = TRUE)
y <- 10 + 2*x + ifelse(w == "H",x-2,-x) + rnorm(N)
data <- data.frame(w,x,y)
```

説明変数を加えたいときには `+` と変数名を使うことができる. 
```{r}
fm <- lm(y~x+w,data = data)
```

今, 帰無仮説のモデルが
$$
y = \alpha + \beta x + u
$$
で, 対立仮説のモデルが
$$
y = \alpha + \beta x + \gamma w + \delta xw + u
$$
のときの検定を実施したい. 
つまり係数が $\gamma = \delta = 0$ という帰無仮説である.

この検定のためには複数の係数がゼロを帰無仮説とするエフ検定を実施する.
エフ検定の実施手順は以下である.
対立仮説の残差自乗和を $SSR$ とし, その自由度を $df$ とする.
自由度は観測数から説明変数の数を減じた数である.
帰無仮説の残差自乗和を $SSR_0$ とし, 制約の数を $q$ とする.
制約の数は帰無仮説の自由度から帰無仮説の自由度を差し引いた数である.
このとき, 以下のF値は帰無仮説が正しいもと自由度 $df$ と $q$ のF分布にしたがう.
$$
\frac{(SSR_0-SSR)/q}{SSR/df}
$$

R でF値は次のようにして算出する. 
```{r}
fm0 <- lm(y~x, data = data)
fm1 <- lm(y~x*w, data = data)
dof <-  df.residual(fm1)
q <- df.residual(fm0) - dof
SSR0 <- deviance(fm0)
SSR <- deviance(fm1)
(F <- ((SSR0 - SSR)/q)/(SSR/dof))
```

決定係数は $R^2 = 1- RSS/\sum(y_i-\bar{x})^2$ なので,
エフ値は, 制約ありモデルの決定係数を $R^2_0$ として
$$
\frac{(R^2_0-R^2)/q}{(1-R^2)/df}
$$
でも計算できる.
```{r}
((rsquared(fm1) - rsquared(fm0))/q)/((1 - rsquared(fm1))/dof)
```

この時のP値は以下である.
```{r}
1 - pf(F, df1 = q,df2 = dof)
```

これらの手順はコマンド `anova` を用いれば簡単に実現できる.
```{r}
anova(fm0, fm1)
```

なお順番を変えても, 検定統計量自体に変更はない.
```{r}
anova(fm1, fm0)
```

特に全ての係数がゼロ $\beta = \gamma = \delta = 0$ という帰無仮説のときの検定統計量はエフ値という.

```{r}
summary(fm1)$fstatistic
(rsquared(fm1)/3)/((1 - rsquared(fm1))/dof)
```


## 作表
基本統計量:
```{r, results='asis'}
mtcars %>% select(mpg, wt, hp, cyl) %>% stargazer(type = "html")
```


```{r}
fm1 <- lm(mpg ~ wt + hp, data = mtcars)
fm2 <- lm(mpg ~ wt * hp, data = mtcars)
fm3 <- update(fm2, .~. + factor(cyl))
```

回帰分析の比較表
```{r, results='asis'}
stargazer(fm1,fm2,fm3,type = "html")
```

